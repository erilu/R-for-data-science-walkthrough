---
title: "R for Data Science Walkthrough Chapters 4-6"
author: "Erick Lu"
output: 
  github_document:
    html_preview: false
    toc: true
    toc_depth: 2
    fig_width: 5
    fig_height: 3.5
---

This my walkthrough for the book: _R for Data Science_ by Hadley Wickham and Garrett Grolemund. It contains my answers to their exercises, some highlights from the book that I found useful, and some of my own notes and data explorations. Here I will go through chapters 4-6.

# Chapter 4

## 4.4 Practice

### 1. Why does this code not work?
```{r}
my_variable <- 10
# my_varıable
```
The code does not work because there is a typo in the variable name that you are calling. The letter "i" is not the same in my_var(i)able.

### 2. Tweak each of the following R commands so that they run correctly:

Changed "dota" to "data", "fliter" to "filter", "=" to "==", and "diamond" to "diamonds"

```{r chap4_exercises}
library(tidyverse)

ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))

filter(mpg, cyl == 8)
filter(diamonds, carat > 3)
```

### 3. Press Alt + Shift + K. What happens? How can you get to the same place using the menus?

This opens up a list of the keyboard shortcuts! Very useful. Using the menus, either type "shorcut" into the search bar under help, or find it under: tools: keyboard shortcuts help.

# Chapter 5

The data that we will work with in chapter 5 is from the nycflights13 package.

```{r}
library(tidyverse)
library(nycflights13)

flights
```

## 5.2 Filter rows with filter()

filter() will subset obervations based on their values. I think it works a lot like the which() function in base R (ie: data[which(data$variable > value),] ). Below is a way to do the same thing using either filter() or base R which().

```{r}
# tidyverse filter() output
filter(flights, month == 1, day == 1)

# base R way to get the same output
flights[which(flights$month ==1 & flights$day ==1),]
```

## 5.2.1 Comparisons

A safer way for comparing two numeric vectors is the near() function in dplyr. For example, if running this comparison:

```{r}
sqrt(2) ^ 2 == 2
1/49 * 49 == 1
```

We see that what we would normally regard as true is specified as FALSE in R, due to floating point precision issues. The near() function will allow more tolerance.

```{r}
near(sqrt(2) ^ 2,  2)
near(1 / 49 * 49, 1)
```

## 5.2.2 Logical Operators

There are many ways to combine "and", ```&```, "or", ```|```, and "not",```!``` to filter out observations in a data table.

```{r}
#following two filter functions give same output
filter(flights, month == 11 | month == 12)
filter(flights, month %in% c(11,12))

#following two filter functions give same output
filter(flights, !(arr_delay > 120 | dep_delay > 120))
filter(flights, arr_delay <= 120 & !dep_delay > 120)
```


## 5.2.3 Missing values

Missing values are represented as NA. NA values are "contagious," meaning that any operation or comparison with NA will also return NA. If a data frame contains NA values, they will not be returned by filter() unless specifically asked for, using is.na()

```{r}
df <- tibble(x = c(1, NA, 3))
filter(df, x > 1)
#> # A tibble: 1 × 1
#>       x
#>   <dbl>
#> 1     3
filter(df, is.na(x) | x > 1)
```


## 5.2.4 Exercises

### 1. Find all flights that

* Had an arrival delay of two or more hours

```{r}
# arr_delay is in minutes, so 120 for two hours
filter(flights, arr_delay >= 120)
```

* Flew to Houston (IAH or HOU)

```{r}
filter(flights, dest == "IAH" | dest == "HOU")
```

* Were operated by United, American, or Delta

```{r}
#find all unique carriers:
unique(flights$carrier)

#Symbol for United = UA, American = AA, Delta = DL
filter (flights, carrier %in% c("UA", "AA","DL"))
```


* Departed in summer (July, August, and September)

```{r}
filter (flights, month >= 7 & month <=9)
# test whether the output only has months 7 8 9 to check our work.
unique(filter (flights, month >= 7 & month <=9)$month)
```


* Arrived more than two hours late, but didn’t leave late

```{r}
filter (flights, arr_delay > 120, dep_delay <=0)
#looks like combining the two arguments into one does the same thing.
filter(flights, arr_delay > 120 & dep_delay <=0)
```

* Were delayed by at least an hour, but made up over 30 minutes in flight

```{r}
# if delayed 60 minutes but made up at least 30, expect arr_delay to be less than 60-30 = 30 min
filter (flights, dep_delay >= 60, arr_delay < 30)

```

* Departed between midnight and 6am (inclusive)

```{r}
times <- filter (flights, dep_time >= 0 & dep_time <= 600)
times
#check if it worked
range(times$dep_time)
```

* Another useful dplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the previous challenges?

?between() states that this is a shortcut to perform the same function as ```x >= left & x <= right```, for ```between(x, left, right)```. I will use between() to produce the same result as in the previous bullet point for flights departing between midnight and 6am.

```{r}
filter(flights, between(dep_time, 0, 600))
```


### 2. How many flights have a missing dep_time? What other variables are missing? What might these rows represent?


```{r}
filter(flights, is.na(dep_time))
```

The flights with missing dep_time also have missing arr_time and air_time, suggesting that these were cancelled flights.

### 3. Why is NA ^ 0 not missing? Why is NA | TRUE not missing? Why is FALSE & NA not missing? Can you figure out the general rule? (NA * 0 is a tricky counterexample!)

Since NA represents an unknown value, it still obeys certain rules as if it were a known value. Since any number to the power of 0 is 1, NA^0 returns the value 1, which will make the code ```filter(flights, dep_time == NA^0)``` return all the flights that departed at time 0001. NA | TRUE is an expression that evaluates to TRUE, because the logical operator will evaluate whether either side has a TRUE value. This would return all the data points in the data frame. FALSE & NA returns FALSE based on the same premise as the previous item. Since FALSE exists on either side of the & logical operator, it is evaluated as FALSE. The general (but not concrete) rule is that modifying NA with a logical operator in the form ```NA <operator> value``` will evaluate to either TRUE or FALSE, returning not missing values, and that NA will still abide by certain rules that any value would abide by. NA*0, however, is an exception beacuse this still evaluates to NA, whereas other values would evaluate to 0. 

```{r}
NA^0
NA | TRUE
FALSE & NA
NA*0
filter(flights, dep_time == NA^0)
filter(flights, dep_time == NA | TRUE)
```


## 5.3 Arrange rows with arrange()

arrange() will return a data frame with the observations sorted by the variable you specify. It functions similarly to the order() function in base R. Below are two ways to get the same sorted dataframe using arrange() and order(). You can see that arrange() makes things a little simpler to read. For the base R order() function, it will only return a sorted list of values, so you have to pass them into the flights[] frame to obtain all the values for the sorted data.

```{r}
# using arrange()
arrange(flights, desc(arr_delay))
# using base R order()
flights[order(flights$arr_delay, decreasing = T),]
```

Missing values (NA) are placed at the end for arrange()


```{r}
df <- tibble(x = c(5, 2, NA))
arrange(df, x)

arrange(df, desc(x))

```


## 5.3.1 Exercises

### 1. How could you use arrange() to sort all missing values to the start? (Hint: use is.na()).

```{r}
arrange(flights, desc(is.na(dep_time)))
```

### 2. Sort flights to find the most delayed flights. Find the flights that left earliest.

```{r}
# most delayed flights
arrange(flights, desc(dep_delay))

# flights that left earliest (least amount of delay)
arrange(flights, dep_delay)
```

### 3. Sort flights to find the fastest flights.

```{r fastest_flights_arrange}
# fastest flights
arrange (flights, arr_delay)

# find out which airlines had the top 1,000 fastest flights
top1000_fastest <- arrange(flights,arr_delay)[1:1000,]
ggplot (top1000_fastest, aes ( x = carrier, fill = carrier))+
  geom_bar()

# compare total air time vs dep_delay to see if there are any trends between airlines
ggplot (top1000_fastest, aes (x = arr_delay, y = air_time))+
  geom_point( aes (color = carrier))

```

Based on the bar plot, within the top 1000 flights that landed early, AA, DL, and UA have more than other airlines. Looking at the scatterplot, it seems UA generally has medium-length flights that arrive ahead of schedule, whereas HA has very long flights that arrive ahead of schedule, and 9E has very short flights that arrive ahead of schedule.

### 4. Which flights travelled the longest? Which travelled the shortest?

The shortest flights were from EWR to BDL, taking around 22 minutes. Of the top 100 shortest flights, flight number 4276 was the most frequent. The longest flights were from JFK to HNL or EWR to HNL, and lasted around 654 minutes. Of the top 100 longest flights, flight number 51 was the most frequent.

```{r}
# flights that travelled the shortest
shortest <- arrange(flights, air_time)[1:100,]
shortest
# find the most frequent flight number for top 100 shortest flights.
arrange(count(shortest, flight),desc(n))
# flights that travelled the longest
longest <- arrange(flights, desc(air_time))[1:100,]
longest
# find the most frequent flight number for top 100 shortest flights.
arrange(count(longest, flight),desc(n))

# get average flight time for top 100 shortest / longest flights
mean(shortest$air_time)
mean(longest$air_time)
```


## 5.4 Select columns with select()

The select() function allows you to select a subset of columns (variables) from your data frame and return a new data frame with these selected columns. This works similarly to using indexes to pull out columns from a data frame in base R. For example, here is a way to do the same thing both ways:

```{r}
# Select columns by name
select(flights, year, month, day)

# use base R to do the same thing
flights[,c("year","month","day")]
```

Select seems to be more versatile if you want to do other things quickly, like combining it with ends_with(), starts_with(), contains(), matches(), num_range(), etc.

```{r}
# select multiple columns using colon
select(flights, year:day)
# select columns that end with a phrase
select(flights, ends_with("time"))
```

A variant of select(), rename(), can rename column variables. This seems very useful.

```{r}
rename(flights, tail_num = tailnum)
```

To move variables to the leftmost side using select(), use the everything() function in conjunction with the variables you are pulling out.


```{r}
select(flights, carrier, flight, everything())
```


## 5.4.1 Exercises
### 1. Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.

```{r}
# standard way to select
select (flights, dep_time, dep_delay, arr_time, arr_delay)
# select using starts_with()
select (flights, starts_with("dep"),starts_with("arr"))
#can also do some less efficient combination of contains() and subtracting columns.
select (flights, contains("dep_"), contains("arr_"),-contains("sched"))
```


### 2. What happens if you include the name of a variable multiple times in a select() call?

```{r}
select(flights, dep_time, dep_time)
```

It looks like you will only get the variable one time (it will not duplicate).

### 3. What does the one_of() function do? Why might it be helpful in conjunction with this vector?

one_of() function takes in a vector of characters, which could be names of columns that you want to select. This way, you dont have to have so many arguments in select(). You can pre-make a vector with the columns you want, then select one_of(vars), as shown here. However, I tried just putting the vector in as a argument without one_of() and it gave the same output.
```{r}
vars <- c("year", "month", "day", "dep_delay", "arr_delay")
#use the one_of() function to select each of the specified columns in vars
select(flights, one_of(vars))

# it seems like this also works to give the same output.
select(flights, vars)

```

### 4. Does the result of running the following code surprise you? How do the select helpers deal with case by default? How can you change that default?

```{r}
select(flights, contains("TIME"))
```

The code returns columns that have lowercase time in them, even though we specified TIME in uppercase. This is not surprising because ?contains() specifies that "ignore.case = TRUE" by default. To get only columns with uppercase TIME, we can write:

```{r}
select(flights, contains("TIME", ignore.case = FALSE))
```

Since no columns in the flights data frame have the uppercase TIME in them, nothing is returned.


## 5.5 Add new variables with mutate()

```{r}
# view the data as a spreadsheet with View() - note capital V
# View(flights)

# select a subset of columns so data is easier to work with for demonstration purposes
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)
flights_sml

```

To add new columns to the dataset that are functions of existing columns, use the mutate() function. You can even refer to newly created columns in the same call, which seems like magic. The new columns are appended to the end of the data frame.

```{r}
mutate(flights_sml,
  gain = arr_delay - dep_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
```

To keep only the newly created columns, use transmute():

```{r}
transmute(flights,
  gain = arr_delay - dep_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
```


In general, all functions or operators that can be applied to vectors and return vectors with the same number of values as output can be used with mutate() or transmute(). Examples include arithmetic operators, modular arithmetic, logs, offsets (lead() and lag()), cumulative sum/averages, logical comparisons (returns boolean for each value in vector),  Another provided example:

```{r}
# convert dep_time to hours and minutes using modulus and remainder
transmute(flights,
  dep_time,
  hour = dep_time %/% 100,
  minute = dep_time %% 100
)
```


```{r}
y <- c(1, 2, NA, 2,  4, 3)
min_rank(y)
rank(y)
```


## 5.5.2 Exercises
### 1. Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they’re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight.

To convert military hours to minutes since midnight, first find how many hours it's been (%/% 100), then multiply that by 60 to get the minutes, then add the remainin minutes (%% 100). Below is a table of the old columns and new columns.

```{r}
transmute(flights,
          dep_time,
          sched_dep_time,
          dep_time_min = (dep_time %/% 100)*60 + (dep_time %% 100),
          sched_dep_time_min = (dep_time %/% 100)*60 + (dep_time %% 100)
)
```


### 2. Compare air_time with arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it?

I expect to see that arr_time - dep_time = air_time. However, the values do not match because arr_time - dep_time returns the amount of time in hours:minutes, whereas air_time is in total minutes. We would have to convert the output into total minutes. However, this still does not fix the problem. There is also the issue of time zones. Depending on where the plane flew, the air_time could be consistent but the arr_time could be way off. We can see from the first two rows that two different flights that had different arr_time and dep_times had the same air_time!

```{r}
# gives time in hours:min
transmute (flights, arr_time, dep_time, air_time, my_air_time = arr_time - dep_time)

# convert to total minutes
transmute (flights, arr_time, dep_time, air_time, my_air_time = ((arr_time %/% 100)*60 + arr_time %% 100) - ((dep_time %/% 100)*60 + dep_time %% 100))
```

### 3. Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?

I would expect that dep_time - sched_dep_time, converted to minutes, would equal dep_delay.

```{r}
transmute (flights, dep_time, sched_dep_time, dep_delay, my_dep_delay = ((dep_time %/% 100)*60 + dep_time %% 100) - ((sched_dep_time %/% 100)*60 + sched_dep_time %% 100))
```


### 4. Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank().

I suppose we could arrange dep_delay to find the top most delayed flights. Using min_rank() will rank the delayed flights - if we rank the delayed flights and then sort on the rank, we see that the most delayed flight is rank 328521, with a delay of 1301 minutes. The default ties.method for min_rank is "min".

```{r}
transmute(flights, dep_delay, rank_delay = min_rank(dep_delay)) 

sorted_flights <- transmute(flights, dep_delay, rank_delay = min_rank(dep_delay)) %>% arrange(desc(rank_delay))
sorted_flights[1:10,]

```


### 5. What does 1:3 + 1:10 return? Why?

```{r}
# returns error
 1:3 + 1:10
# if adding to a multiple:
1:3 + 1:9
```

### 6. What trigonometric functions does R provide?

Taken from the R documentation: "These functions give the obvious trigonometric functions. They respectively compute the cosine, sine, tangent, arc-cosine, arc-sine, arc-tangent, and the two-argument arc-tangent."

```cospi(x), sinpi(x), and tanpi(x), compute cos(pi*x), sin(pi*x), and tan(pi*x).```

## 5.6 Grouped summaries with summarise()

summarise(), in its simplest usage, can perform a function on a column in the data set and return the output as a single row:

```{r}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

A more advanced usage of summarise() is when paired with group_by(). This will return the function on each of the subgroups from group_by(), and giving statistics "by group". Looking at the group_by() output, there doesnt seem to be any striking difference between the original flights data frame and the grouped data frame. The result of using group_by() is not immediately apparent unless paired with summarise(). It would be interesting to know what other usages group_by() can have.

```{r}
by_day <- group_by(flights, year, month, day)
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

### 5.6.1 Combining multiple operations with the pipe

Learning how to use the pipe - the pipe, or ```%>%``` can be used to more efficiently run sequential of functions on a variable and its output. This reduces the amount of naming intermediate variables we have to do. If we care about intermediate variables (ie, performing other analysis or using the vairable for other purposes) then I would not use the pipe. If i do not care about the intermeidate variables and want to quickly get output, the pipe would be useful.

Here is the provided example about writing code without or with pipes:

```{r}
# not using pipes - note all the intermediate variables
by_dest <- group_by(flights, dest)
delay <- summarise(by_dest,
  count = n(),
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
)
delay <- filter(delay, count > 20, dest != "HNL")

```


```{r}
# using pipes
delay <- flights %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>% 
  filter(count > 20, dest != "HNL")

# It looks like delays increase with distance up to ~750 miles 
# and then decrease. Maybe as flights get longer there's more 
# ability to make up delays in the air?
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) +
  geom_smooth(se = FALSE)
#> `geom_smooth()` using method = 'loess'
```

### 5.6.2 Missing values

Without setting na.rm, the following code does not produce any means using summarse(). Instead, all the values under the mean column are NA. This is beacuse aggregating NA with any other numbers will return NA. We must call na.rm = TRUE in the summarise() function to produce meaningul values.

```{r}
# without na.rm
flights %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))

# with na.rm
flights %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay, na.rm = TRUE))
```


To get a data frame without any of the NA values (cancelled flights):

```{r}
# 2 ways to use filter() to get the non-cancelled flights
(not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay)))
(not_cancelled2 <- flights %>% 
  filter(!(is.na(dep_delay) | is.na(arr_delay))))
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))
```



### 5.6.3 Counts

When using summarise, its important to know how many observations each summary value was being computed on. If the counts are low, the variance of the summary value might be very high, and the results may not be as interpretable or reliable.

```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay)
  )

ggplot(data = delays, mapping = aes(x = delay)) + 
  geom_freqpoly(binwidth = 10)
```

Here we see that some flights have very high delay values, but these flights also don't have very many counts. To count how many observations each summary value was computed on, use the n() function in summarize()

```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )

# basically the previous graph flipped on its side
ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10)
```

We can filter out the observations based on less than 25 counts using filter(), and then pipe the result into ggplot.

```{r}
delays %>% 
  filter(n > 25) %>% 
  ggplot(mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1/10) +
    geom_smooth(se = FALSE)
```


### 5.6.4 Useful summary functions

Types of functions that you can use in summarize are: mean(), median(), sd(), IQR(), mad(), min(), quantile(), max(), first(), nth(), last(), n(), sum (!is.na()), counts of logical variables (sum(x>20)), and more. And subsetting values prior to performing the function using > <, etc.

When subsetting, it is important not to be confused between getting the mean of the subsetted values vs the proportion of the subsetted values that satisfy the condition:

```{r}
# get mean delay of flights delayed by more than 60 hours
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    avg_delay_over60 = mean(arr_delay[arr_delay > 60]) # the average positive delay
  )

# get proportion of flights delayed for more than 60 hours
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(hour_perc = mean(arr_delay > 60))

```

The example in the book provides two ways to find the min & max observation for each group of flights (although the output is in a different format), which I thought was interesting.

```{r}
# using summarise()
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first_dep = first(dep_time), 
    last_dep = last(dep_time)
  )
# using mutate() & filter()
not_cancelled %>% 
  group_by(year, month, day) %>% 
  mutate(r = min_rank(desc(dep_time))) %>% 
  filter(r %in% range(r))


```

Also, I thought it was very useful how you can weight counts based on another variable, so that you can get a sum of total values of a different variable grouped on another set of variables (basically a shorter way to use group_by and summarize-sum() together, as shown below).

```{r}
# sum using weighted counts()
not_cancelled %>% 
  count(tailnum, wt = distance)

# sum using group_by and summarise() + sum()
not_cancelled %>%
  group_by(tailnum) %>%
  summarise(sum_distances = sum(distance))

```

To count unique values, use n_distinct():

```{r}
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(carriers = n_distinct(carrier)) %>% 
  arrange(desc(carriers))
```

### 5.6.5 Grouping by multiple variables

You can progressively peel off groupings by re-calling summarise() on previous summarise() tables. Must be careful to use aggregation functions that make sense, like sum(), and not rank-based statistics like median(). They initial grouped data frame can be ungrouped manually as well.

```{r}
# group the data
daily <- group_by(flights, year, month, day)

# use summarise() to get metric per group
(per_day   <- summarise(daily, flights = n()))

# use summarise() on the previous summary to get metric one level up
(per_month <- summarise(per_day, flights = sum(flights)))

# use summarise() on the previous summary again to get metric another level up
(per_year  <- summarise(per_month, flights = sum(flights)))

# ungroup the data
daily %>% 
  ungroup() %>%             # no longer grouped by date
  summarise(flights = n())  # all flights
```


## 5.6.7 Exercises
### 1. Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios:

* A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.

To examine how flights behave, I would group by the flight number (flight), then perform analyses on the grouped flights. When looking at the data, there are some flights that are always 15 minutes late! However, these flights had less than 20 total data points. Filtering out the flights with less than 20 total points, we can see that flights with less data points tend to have a higher proportion of delays, whereas flights with many data points have an overall lower proportion of delayed flights. The proportion of flights that are early 15 minutes also follows a similar trend, with flights that have flown fewer times tending to have larger proportion of those flights 15 minutes early.

```{r}
by_flight <- not_cancelled %>%
  group_by(flight) %>%
  summarise(
    late_15 = mean(dep_delay >= 15),
    early_15 = mean(dep_delay <= -15),
    n = n()
  ) %>%
  arrange(desc(late_15))
by_flight

# filter out flights with less than 20 total flights, then plot delays vs total counts
ggplot(filter(by_flight, n > 20), aes (x = n, y = late_15)) +
  geom_point( aes(alpha = 1/5))

# filter out flights with less than 20 total flights, then plot delays vs total counts
ggplot(filter(by_flight, n > 20), aes (x = n, y = early_15)) +
  geom_point( aes(alpha = 1/5))

# find the flights that are either 15 minutes late with proportion 0.5 (no results)
filter (by_flight, late_15 == 0.5, early_15 == 0.5)

```

* A flight is always 10 minutes late.

The code below will give the flight numbers of all the flights that have been at least 10 minutes late 100% of the time. We can see that the number of counts is low for all of the flights returned.

```{r}
by_flight <- not_cancelled %>%
  group_by(flight) %>%
  summarise(
    late_10 = mean(dep_delay > 10),
    n = n()
  ) %>%
  filter(late_10 == 1)
by_flight
```

* A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.

This can be solved by using the same code from the first bullet point, except changing the parameters to 30 minutes instead of 15.

* 99% of the time a flight is on time. 1% of the time it’s 2 hours late.

Below is code that finds flights that are late at least 2 hours exactly 1% of the time.

```{r}
by_flight <- not_cancelled %>%
  group_by(flight) %>%
  summarise(
    late_120 = mean(dep_delay >= 120),
    n = n()
  ) %>%
  filter(late_120 == 0.01)
by_flight
```

Which is more important: arrival delay or departure delay?

In my opinion, time of arrival of the flight is more important than departure delay, since you will probably have planned an itinerary that has a next step that depends on the time of arrival rather than the time of departure.

### 2. Come up with another approach that will give you the same output as not_cancelled %>% count(dest) and not_cancelled %>% count(tailnum, wt = distance) (without using count()).

```{r}
# same output as: not_cancelled %>% count(dest)
not_cancelled %>%
  group_by(dest) %>%
  summarize(
    n = n()
  )

# same output as: not_cancelled %>% count(tailnum, wt = distance)
not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    n = sum(distance)
  )

```


### 3. Our definition of cancelled flights (is.na(dep_delay) | is.na(arr_delay) ) is slightly suboptimal. Why? Which is the most important column?

If a flight still took place and there was an error in entering the dep_delay or arr_delay, we would have thrown out the flight. A more important column to look at may be air_time - a flight cannot have had air_time if it never flew.

### 4. Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?

To answer the first part of the question, this code returns a table with the number of cancelled flights per day. Plotting the data as a time series, we can see that there is some periodic trend in which spikes of large numbers of cancelled flights occur.

```{r}
# find number of cancelled flights per day

cancelled_flights <- filter (flights, is.na(air_time))
(per_day_cancelled <- cancelled_flights %>%
  group_by(year, month, day) %>%
  summarize(n = n()))

ggplot (per_day_cancelled)+
  geom_boxplot(aes (x = day, y = n, group = day))

ggplot (per_day_cancelled)+
  geom_line(aes(x = c(1:length(per_day_cancelled$n)), y = n))

```

To find the proportion of cancelled flights per day, first group flights by year,month,day using group_by(), then for each day, count the total number of flights and number of cancelled flights using summarize(), and then use mutate() to calculate the proportion by dividing the number of cancelled flights by the total flights. Based on the graph of average_delay vs proportion_cancelled, we can see that there is a positive correlation in which days that have overall higher delays also have overall higher proportion of cancelled flights.

```{r}
#proportion of cancelled flights per day

(proportion_cancelled <- flights %>%
  group_by(year,month,day) %>%
  summarize (
    average_delay = mean(dep_delay, na.rm = T),
    num_cancelled = sum (is.na(air_time)),
    total_flights = n()
  ) %>%
  mutate ( prop_cancelled = num_cancelled/total_flights))

ggplot(proportion_cancelled, aes (average_delay, prop_cancelled))+
  geom_point()
```


### 5. Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights %>% group_by(carrier, dest) %>% summarise(n()))

The top 5 carriers with the worst delays are: F9, EV, YV< FL, and WN. If we continue to subset by airport location (see graph), we find that some carriers have higher delays on average without depending on destination, whereas some carriers which fly only to certain destinations have a large dep_delay. One such example is FL, which we see only flies to 3 destinations and has a high dep_delay on average.

```{r}
# find carrier with worst delay
by_carrier <- flights %>%
  group_by(carrier) %>%
  summarize (
    avg_delay = mean(dep_delay, na.rm = T)
  ) %>%
  arrange(desc(avg_delay))
by_carrier

by_carrier_dest <- flights %>%
  group_by(carrier, dest) %>%
  summarize (
    avg_delay = mean(dep_delay, na.rm = T),
    n = n()
  ) %>%
  arrange(desc(avg_delay))
by_carrier_dest

# "stripchart" of average delay grouped by carrier, each point is a destination
ggplot(by_carrier_dest) +
  geom_point (aes(x = carrier, y = avg_delay, color = dest, size = n, alpha = 1/5), position = 'jitter')

```


### 6. What does the sort argument to count() do. When might you use it?

If you set sort = TRUE in count(), it will return the output sorted in descending order of n. This might be useful when trying to find the item with the most occurances when counting, and will save you from having to pipe the data into arrange().

## 5.7 Grouped mutates (and filters)

You can use the group_by() function for purposes other than piping into summarize(). For example, you can use group_by() with filter() to find which items within a group satisfy a certain condition.

```{r}
popular_dests <- flights %>% 
  group_by(dest) %>% 
  filter(n() > 365)
popular_dests

# out of 105 destinations, 77 have had greater than 365 flights
length(unique(flights$dest))
length(unique(popular_dests$dest))
```

This resulting filtered data frame can be further analyzed for per-group metrics.

```{r}
popular_dests %>% 
  filter(arr_delay > 0) %>% 
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% 
  select(year:day, dest, arr_delay, prop_delay)
# not sure if this divides the group sum, or the total sum of all flights
```


## 5.7.1 Exercises
### 1. Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping.

For filter(), the conditional statement in the filter() function will be applied separately to each subgroup, and all the observations corresponding to the subgroups that are TRUE will be returned.

When combined with grouping, mutate seems to be more tricky. The functions do not seem to change if a grouped or ungrouped input is used. It seems that the mutate() would be useful if used on a grouped, filtered table.

```{r}
flights %>%
  group_by(year,month,day) %>%
mutate(  dep_time,
  hour = dep_time %/% 100,
  log_air_time = log(air_time)
)
flights %>%
mutate(  dep_time,
  hour = dep_time %/% 100,
  log_air_time = log(air_time)
)
```


### 2. Which plane (tailnum) has the worst on-time record?

There are over 100 planes which have a 100% record of being delayed, either on departure or arrival.

```{r}

flights %>%
  group_by(tailnum) %>%
  summarize(
    delay_count = sum (dep_delay > 0),
    delay_proportion = mean (dep_delay>0)
  ) %>%
  arrange (desc(delay_proportion))


flights %>%
  group_by(tailnum) %>%
  summarize(
    arr_count = sum (arr_delay > 0),
    arr_proportion = mean (arr_delay>0)
  ) %>%
  arrange (desc(arr_proportion))

```


### 3. What time of day should you fly if you want to avoid delays as much as possible?

To figure this out, we would want to examine the distribution of delays over time to see where the delays are minimized. Plotting time on the x-axis and the mean dep_delay per unit time on the y axis, we can see that from time 500-1000 there are on average less delays than during other times.

```{r}
flights %>%
  group_by(dep_time) %>%
  summarize(
    mean_delay = mean (dep_delay, na.rm = T),
    n = n()
  ) %>%
  arrange (mean_delay) %>%
  ggplot ( aes (dep_time, mean_delay) )+
  geom_point(aes(size = n, alpha = 1/5))
```

### 4. For each destination, compute the total minutes of delay. For each, flight, compute the proportion of the total delay for its destination.

```{r}
# calculate total delay time of delayed flights using summarize()
flights %>%
  filter(dep_delay >0) %>%
  group_by(dest) %>%
  summarize(
    total_delay = sum (dep_delay, na.rm = T)
  )
# calculate total delay time of delayed flights using weighted counts()
flights %>%
  filter(dep_delay >0) %>%
  count(dest, wt = dep_delay)

# first filter for all flights that are delayed, then group by destination
# then calculate dep_delay for flight to destination / sum of all delayed flights within the same destination
# select the rows you want, then arrange based on alphabetical order
flights %>%
  filter(dep_delay >0) %>%
  group_by(dest) %>%
  mutate (prop_delay = dep_delay / sum (dep_delay)) %>%
  select (dest, flight, dep_delay, prop_delay) %>%
  arrange (dest)



```


### 5. Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using lag() explore how the delay of a flight is related to the delay of the immediately preceding flight.

I first filter for flights that are delayed. The flights are already ordered by dep_tiem. I then use mutate() and lag() to bind a new column to the data that shows what the previous delay was for that observation. Then, I plot the current delay vs. the previous delay in a scatterplot. Since there are so many points, it is hard to see the pattern. So, I added a linear regression line to the points (OLS) to visualize any correlation that exists. There is a positive correlation, suggesting that, on average, flights that come immediately after a delayed flight tend to also be delayed. The slope is < 1, suggesting that the delay is less than the previous delay.

```{r}
flights %>%
  filter (dep_delay >0) %>%
  mutate ( prev_delay = lag(dep_delay)) %>%
  ggplot ( aes (x = prev_delay, y = dep_delay))+
  geom_point() +
  geom_smooth(method = 'lm', se = F)

```


### 6. Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?

Flights that are suspiciously fast will have an air_time value that is very small compared to the expected amount of air_time (sched_arr_time - sched_dep_time). To find these flights, first group flights by dest, use mutate() to calculate the expected air_time, and calculate the proportion of the amount of time saved during the flight, (expected_air_time - air_time)/expected_air_time. Use arrange() to sort the flights based on prop_time_saved. If we expected the flight to take two hours but the flight had an air_time of 20 minutes, these flights would show up at the top of each group. We see that there are suspiciously fast flights such as flight 4117 to ALB which took 26 minutes, but was expected to take 72 minutes, saving 63% of the expected flight time. Also, flight 4013 to PHL took 23 minutes but was expected ot take 93. This is suspicious!

```{r}
# calculate the expected air time by converting sched_arr_time and sched_dep_time to minutes, then subtracting.
# if the sched_arr_time was past midnight, we have to add 2400 to the value before subtracting.
# to fix this, I use ifelse() within the mutate function.
expected_times <- not_cancelled %>%
  mutate (expected_air_time = ifelse(sched_arr_time < sched_dep_time, 
                                     ((((sched_arr_time+2400) %/% 100)*60 + (sched_arr_time+2400) %% 100) 
                                      - ((sched_dep_time %/% 100)*60 + sched_dep_time %% 100)), 
                                     (((sched_arr_time %/% 100)*60 + sched_arr_time %% 100) 
                                      - ((sched_dep_time %/% 100)*60 + sched_dep_time %% 100))))
# use grouped arrange() to find suspicous flights with large prop_time_saved for each destination.
expected_times %>%
  group_by(dest) %>%
  mutate( prop_time_saved = (expected_air_time - air_time)/expected_air_time ) %>%
  arrange(desc(prop_time_saved)) %>%
  slice (1:5) %>% # select top 5 fastest flights
  select (dest, flight, sched_dep_time, sched_arr_time, air_time, expected_air_time, prop_time_saved)


```

To compute air time to a flight relative to shortest flight to the destination, I would first take a ratio of the air_time to distance, find out what this value is for the shortest flight (smallest distance), then compare it with the suspicious flights. To find the flights most delayed in the air, subtract arr_delay from dep_delay and compare these values.

```{r}
# compare distance traveled over time 
not_cancelled %>%
  group_by(dest) %>%
  mutate ( dist_over_time = distance/air_time,
           shortest_dest_flight = min (air_time, na.rm = T)) %>%
  arrange (desc(dist_over_time)) %>%
  slice (1:5) %>% 
  select( dest, flight, distance, air_time, dist_over_time, shortest_dest_flight)

# top 5 flights for each destination that are delayed the most in the air
(in_air_delays <- not_cancelled %>%
  group_by(dest) %>%
  mutate (in_air_delay = arr_delay - dep_delay) %>%
  arrange (desc(in_air_delay)) %>%
  slice (1:5) %>% 
  select( dest, flight, arr_delay, dep_delay, in_air_delay))

ggplot(in_air_delays) +
  geom_point (aes(x = dest, y = in_air_delay), position = 'jitter')+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

### 7. Find all destinations that are flown by at least two carriers. Use that information to rank the carriers.

The code below will find the destinations that are flown by at least 2 carriers. The second part of the question is vague--how can carriers be ranked by whether a destination is flown to by 2 more more carriers? It would make more sense to rank the destinations. Below I rank the carriers by the number of destinations they fly to.

```{r}
# destinations that are flown by at least two carriers
not_cancelled %>%
  group_by(dest) %>%
  filter( length(unique(carrier)) >= 2)

# get the same output using the n_distinct() function instead of length(unique())
not_cancelled %>%
  group_by(dest) %>%
  filter( n_distinct(carrier) >= 2)

# carriers that fly to the most destinations:
not_cancelled %>%
  group_by(carrier) %>%
  summarize(
    num_dest = length (unique(dest))
  ) %>%
  arrange (desc(num_dest))

# checking to see if length(unique(dest)) worked by selecting one of the flights and manually counting
EV_flights <- not_cancelled %>%
  filter ( carrier == 'EV')
length(unique(EV_flights$dest))

# we can also group sequentially, if that's what the question is suggesting
not_cancelled %>%
  group_by(dest) %>%
  filter(n_distinct(carrier) >= 2) %>%  # filter for flights to destinations that have more than 2 carriers
  group_by(carrier) %>% # group by carriers in this filtered dataset
  summarize(num_dest = n_distinct(dest)) %>% # find the number of distinct destinations they fly to
  arrange(desc(num_dest)) # sort the output

```


### 8. For each plane, count the number of flights before the first delay of greater than 1 hour.

I would first group by flight, and then select the minimum sched_dep_time for flights that were delayed greater than 60 minutes. Then I would count the number of flights that are less than the minimum sched_dep_time in each group of flights. I used full_join() to map the first flight with delay greater than 1 hour to the original flights table, then used summarize() to count the number of flights that came before this for each group within tailnum.

```{r}
# finds the first occurance of a delay greater than 60 min

min_delay <- flights %>%
  group_by(tailnum) %>%
  filter (dep_delay > 60) %>%
  summarize(
    min_sched_dep =  min (sched_dep_time)
  )

# join the dep_time of the first occurance of the >60min delay to the original table
(joined_delay <- full_join (flights,min_delay, by = "tailnum") %>% arrange (tailnum))

# use summarize() to figure out how many values came before the first delay > 60min (see column num_before_delay60).
joined_delay %>%
  group_by(tailnum) %>%
  summarize(
    num_before_delay60 = sum ( sched_dep_time < min_sched_dep, na.rm = T)
  )

```


Thanks for reading through my walkthrough of chapters 4 - 6! I hope you found my solutions to the exercises informative. A walkthrough of chapters 7 - 8 can be found at [r4ds_chapters7-8_walkthrough.md](https://github.com/erilu/R-for-data-science-walkthrough/blob/master/r4ds_chapters7-8_walkthrough.md).



